<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon-32x32-next.png?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习, 机器学习, 后端, 算法">










<meta property="og:type" content="website">
<meta property="og:title" content="T&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="T&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="T&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>T's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">T's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/26/Graph-Embedding实验/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="青檀">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/26/Graph-Embedding实验/" itemprop="url">Graph Embedding实验</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-26T21:49:54+08:00">
                2019-12-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Graph-Embedding实验"><a href="#Graph-Embedding实验" class="headerlink" title="Graph Embedding实验"></a>Graph Embedding实验</h2><h3 id="1-DeepWalk"><a href="#1-DeepWalk" class="headerlink" title="1. DeepWalk"></a>1. DeepWalk</h3><h4 id="1-实现思路"><a href="#1-实现思路" class="headerlink" title="(1) 实现思路"></a>(1) 实现思路</h4><ul>
<li>利用networkx和pandas读取数据文件并建图</li>
<li>随机选定节点开始Random Walk，形成指定长度的序列</li>
<li>重复多次，构成sentences作为训练样本</li>
<li>利用gensim构建word2vec模型进行训练，得到embeddings向量</li>
</ul>
<h4 id="2-核心代码"><a href="#2-核心代码" class="headerlink" title="(2) 核心代码"></a>(2) 核心代码</h4><p>核心代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_walk</span><span class="params">(start, walk_length)</span>:</span></span><br><span class="line">    path = [start]</span><br><span class="line">    <span class="keyword">while</span> len(path) &lt; walk_length:</span><br><span class="line">        cur = path[<span class="number">-1</span>]</span><br><span class="line">        neigh = list(g.neighbors(cur))</span><br><span class="line">        <span class="keyword">if</span> len(neigh) &gt; <span class="number">0</span> :</span><br><span class="line">            path.append(random.choice(neigh))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> [str(node) <span class="keyword">for</span> node <span class="keyword">in</span> path] </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_deepwalk</span><span class="params">(num_walks, walk_length)</span>:</span></span><br><span class="line">    walks = []</span><br><span class="line">    node = list(g.nodes)</span><br><span class="line">    num_walks = len(node) * num_walks</span><br><span class="line">    print(<span class="string">"node: &#123;&#125;, walks_num: &#123;&#125;"</span>.format(len(node), num_walks))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_walks):</span><br><span class="line">        random.shuffle(list(node))</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> node:</span><br><span class="line">            walks.append(random_walk(n, walk_length))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> walks</span><br></pre></td></tr></table></figure>

<h4 id="3-其他"><a href="#3-其他" class="headerlink" title="(3) 其他"></a>(3) 其他</h4><p>​        由于代码没有进行全面的优化，故与论文给出的实现代码相比运行速度较慢。</p>
<h3 id="2-LINE"><a href="#2-LINE" class="headerlink" title="2. LINE"></a>2. LINE</h3><h4 id="1-实现思路-1"><a href="#1-实现思路-1" class="headerlink" title="(1) 实现思路"></a>(1) 实现思路</h4><ul>
<li>采用keras实现训练</li>
<li>定义损失函数，即两个概率分布的距离（同时进行负采样的优化），采用梯度下降进行训练</li>
<li>定义输入向量，以及嵌入的维度，在模型中添加嵌入层</li>
<li>对于二阶相似性，为每个定点维护两个嵌入的向量（本身及上下文）</li>
</ul>
<h4 id="2-核心代码-1"><a href="#2-核心代码-1" class="headerlink" title="(2) 核心代码"></a>(2) 核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(numNodes, factors)</span>:</span></span><br><span class="line">    left_input = Input(shape=(<span class="number">1</span>,))</span><br><span class="line">    right_input = Input(shape=(<span class="number">1</span>,))</span><br><span class="line">    left_model = Sequential()</span><br><span class="line">    left_model.add(Embedding(input_dim=numNodes + <span class="number">1</span>, output_dim=factors, input_length=<span class="number">1</span>, mask_zero=<span class="literal">False</span>))</span><br><span class="line">    left_model.add(Reshape((factors,)))</span><br><span class="line">    right_model = Sequential()</span><br><span class="line">    right_model.add(Embedding(input_dim=numNodes + <span class="number">1</span>, output_dim=factors, input_length=<span class="number">1</span>, mask_zero=<span class="literal">False</span>))</span><br><span class="line">    right_model.add(Reshape((factors,)))</span><br><span class="line">    left_embed = left_model(left_input)</span><br><span class="line">    right_embed = left_model(right_input)</span><br><span class="line">    left_right_dot = Dot(axes=<span class="number">1</span>)([left_embed, right_embed])</span><br><span class="line">    model = Model(input=[left_input, right_input], output=[left_right_dot])</span><br><span class="line">    embed_generator = Model(input=[left_input, right_input], output=[left_embed, right_embed])</span><br><span class="line">    <span class="keyword">return</span> model, embed_generator</span><br></pre></td></tr></table></figure>

<h4 id="3-其他-1"><a href="#3-其他-1" class="headerlink" title="(3) 其他"></a>(3) 其他</h4><p>​        论文中提到的优化和采样算法借鉴了word2vec中的优化思想，是简化复杂网络嵌入的一种有力手段，论文中同时使用了O(1) 时间复杂度的Alias Sampling算法。</p>
<h3 id="3-node2vec"><a href="#3-node2vec" class="headerlink" title="3. node2vec"></a>3. node2vec</h3><h4 id="1-实现思路-2"><a href="#1-实现思路-2" class="headerlink" title="(1) 实现思路"></a>(1) 实现思路</h4><ul>
<li>与LINE不同，本算法中的给定点的embedding向量在不同的场合下都是相同的，故只需定义一个输入层和嵌入层</li>
<li>node2vec使用参数p和q控制游走的策略，使游走产生的序列介于BFS和DFS之间，当p=q=1时为DeepWalk</li>
<li>得到游走的序列后，采用Skip-gram模型进行训练</li>
<li>使用负采样优化</li>
</ul>
<h4 id="2-核心代码-2"><a href="#2-核心代码-2" class="headerlink" title="(2) 核心代码"></a>(2) 核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">node2vec_walk</span><span class="params">(self, walk_length, start_node)</span>:</span></span><br><span class="line">        G = self.G</span><br><span class="line">        alias_nodes = self.alias_nodes</span><br><span class="line">        alias_edges = self.alias_edges</span><br><span class="line">        walk = [start_node]</span><br><span class="line">        <span class="keyword">while</span> len(walk) &lt; walk_length:</span><br><span class="line">            cur = walk[<span class="number">-1</span>]</span><br><span class="line">            cur_nbrs = list(G.neighbors(cur))</span><br><span class="line">            <span class="keyword">if</span> len(cur_nbrs) &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> len(walk) == <span class="number">1</span>:</span><br><span class="line">                    walk.append(</span><br><span class="line">                        cur_nbrs[alias_sample(alias_nodes[cur][<span class="number">0</span>], alias_nodes[cur][<span class="number">1</span>])])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    prev = walk[<span class="number">-2</span>]</span><br><span class="line">                    edge = (prev, cur)</span><br><span class="line">                    next_node = cur_nbrs[alias_sample(alias_edges[edge][<span class="number">0</span>],</span><br><span class="line">                                                      alias_edges[edge][<span class="number">1</span>])]</span><br><span class="line">                    walk.append(next_node)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> walk</span><br></pre></td></tr></table></figure>

<h4 id="3-其他-2"><a href="#3-其他-2" class="headerlink" title="(3) 其他"></a>(3) 其他</h4><p>​        node2vec算法使用超参数p和q控制当前节点的游走策略，使其介于DeepWalk的DFS和LINE的BFS之间，同时考虑了节点的结构特性和功能特性。在实现时需要先预处理出概率转移矩阵，从而进行负采样优化。</p>
<h3 id="4-struc2vec"><a href="#4-struc2vec" class="headerlink" title="4. struc2vec"></a>4. struc2vec</h3><h4 id="1-实现思路-3"><a href="#1-实现思路-3" class="headerlink" title="(1) 实现思路"></a>(1) 实现思路</h4><ul>
<li>struc2vec从空间角度考虑节点的关系，而不仅仅是从相邻的角度。</li>
<li>构建节点的有序度序列，采用<strong>Dynamic Time Warping</strong>方法来衡量两个序列的距离</li>
<li>按照论文中提出的方法建立层次带权图</li>
<li>在上一步建立出的图中进行随机游走，获得采样的序列</li>
<li>优化</li>
</ul>
<h4 id="2-核心代码-3"><a href="#2-核心代码-3" class="headerlink" title="(2) 核心代码"></a>(2) 核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_context_graph</span><span class="params">(self, max_num_layers, workers=<span class="number">1</span>, verbose=<span class="number">0</span>,)</span>:</span></span><br><span class="line">       pair_distances = self._compute_structural_distance(</span><br><span class="line">           max_num_layers, workers, verbose,)</span><br><span class="line">       layers_adj, layers_distances = self._get_layer_rep(pair_distances)</span><br><span class="line">       pd.to_pickle(layers_adj, self.temp_path + <span class="string">'layers_adj.pkl'</span>)</span><br><span class="line">       layers_accept, layers_alias = self._get_transition_probs(</span><br><span class="line">           layers_adj, layers_distances)</span><br><span class="line">       pd.to_pickle(layers_alias, self.temp_path + <span class="string">'layers_alias.pkl'</span>)</span><br><span class="line">       pd.to_pickle(layers_accept, self.temp_path + <span class="string">'layers_accept.pkl'</span>)</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">prepare_biased_walk</span><span class="params">(self,)</span>:</span></span><br><span class="line">       sum_weights = &#123;&#125;</span><br><span class="line">       sum_edges = &#123;&#125;</span><br><span class="line">       average_weight = &#123;&#125;</span><br><span class="line">       gamma = &#123;&#125;</span><br><span class="line">       layer = <span class="number">0</span></span><br><span class="line">       <span class="keyword">while</span> (os.path.exists(self.temp_path+<span class="string">'norm_weights_distance-layer-'</span> + str(layer)+<span class="string">'.pkl'</span>)):</span><br><span class="line">           probs = pd.read_pickle(</span><br><span class="line">               self.temp_path+<span class="string">'norm_weights_distance-layer-'</span> + str(layer)+<span class="string">'.pkl'</span>)</span><br><span class="line">           <span class="keyword">for</span> v, list_weights <span class="keyword">in</span> probs.items():</span><br><span class="line">               sum_weights.setdefault(layer, <span class="number">0</span>)</span><br><span class="line">               sum_edges.setdefault(layer, <span class="number">0</span>)</span><br><span class="line">               sum_weights[layer] += sum(list_weights)</span><br><span class="line">               sum_edges[layer] += len(list_weights)</span><br><span class="line">           average_weight[layer] = sum_weights[layer] / sum_edges[layer]</span><br><span class="line">           gamma.setdefault(layer, &#123;&#125;)</span><br><span class="line">           <span class="keyword">for</span> v, list_weights <span class="keyword">in</span> probs.items():</span><br><span class="line">               num_neighbours = <span class="number">0</span></span><br><span class="line">               <span class="keyword">for</span> w <span class="keyword">in</span> list_weights:</span><br><span class="line">                   <span class="keyword">if</span> (w &gt; average_weight[layer]):</span><br><span class="line">                       num_neighbours += <span class="number">1</span></span><br><span class="line">               gamma[layer][v] = num_neighbours</span><br><span class="line">           layer += <span class="number">1</span></span><br><span class="line">       pd.to_pickle(average_weight, self.temp_path + <span class="string">'average_weight'</span>)</span><br><span class="line">       pd.to_pickle(gamma, self.temp_path + <span class="string">'gamma.pkl'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-其他-3"><a href="#3-其他-3" class="headerlink" title="(3) 其他"></a>(3) 其他</h4><p>struc2vec从结构特征方面入手完成Graph Embedding，根据简单的测试和比较，效果提升，但是需要做出更多的时间和空间方面的优化。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/26/CMU 15645: Data Storage(1)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="青檀">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/26/CMU 15645: Data Storage(1)/" itemprop="url">CMU 15645|Data Storage(1)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-26T20:36:15+08:00">
                2019-12-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Database-System/" itemprop="url" rel="index">
                    <span itemprop="name">Database System</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-存储"><a href="#1-存储" class="headerlink" title="1 存储"></a>1 存储</h2><p>CMU 15645课程要求实现一个面向磁盘(disk-oriented)的DBMS，因此假定数据存放在非易失性的磁盘中。</p>
<p>根据存储介质的易失性和非易失性，将存储层次划分为以下两种类别：        </p>
<ul>
<li>易失性设备：易失性指当机器断电时，存储的数据也随之丢失。而此类设备往往支持按字节寻址的快速随机访问，程序可以根据字节地址取出其中的数据。这里通常用它指代内存。（这并不代表易失性设备只有内存，其他如寄存器、CPU cache等）</li>
<li>非易失性设备：不必持续供电来存储数据（即数据不会因为断电而丢失），通常是按块/页寻址的。因此想要读入某处地址的数据，就必须同时读取所在的整块/页的数据。通常是顺序访问的（即不可以随机访问）。这里通常用它指代磁盘。</li>
</ul>
<p>由于数据存储在磁盘上，DBMS就必需负责完成数据在磁盘和内存之间的交换工作。</p>
<h2 id="2-面向磁盘的DBMS概括"><a href="#2-面向磁盘的DBMS概括" class="headerlink" title="2 面向磁盘的DBMS概括"></a>2 面向磁盘的DBMS概括</h2><p>数据库文件中的数据按页组织，第一页是页目录(directory page)。为了对数据进行操作，DBMS通过缓存池(buffer pool)将数据存到内存中，缓存池管理数据在内存和磁盘之间的换入换出。DBMS通过执行引擎(execution engine)来进行查询操作，查询引擎向缓存池请求特定的页，缓存池则将该页换入内存，并返回一个指向该页的指针，同时缓存池也要确保查询引擎操作的页已经存放在内存中。</p>
<h2 id="3-DBMS-与-OS-的对比"><a href="#3-DBMS-与-OS-的对比" class="headerlink" title="3 DBMS 与 OS 的对比"></a>3 DBMS 与 OS 的对比</h2><p>DBMS的设计目标之一就是保证数据库的大小超过可用内存的大小。由于磁盘的读写开销较大，因此DBMS需要在从磁盘在获取数据时能够处理其他的查询操作。</p>
<p>为了实现这一目标，可以利用mmap(内存映射)实现虚拟内存，将文件的内容映射到进程的地址空间中。此时OS负责页的换入和换出，但是如果mmap发生了页故障，就会阻塞整个进程。因此比起OS，更应该由DBMS自己来控制流程，它比OS更清楚有关的数据访问和查询操作。</p>
<p>但是可以利用OS进行如下操作：</p>
<ul>
<li>madvise: 通知OS准备读某些特定的页。</li>
<li>mlock: 通知OS不要将内存换出到磁盘。</li>
<li>msync: 通知OS将内存内容刷新到磁盘上。</li>
</ul>
<p>虽然OS可以提供某些DBMS需要的功能，但是由DBMS本身实现相关的过程可以使DBMS具有更好的控制能力和性能表现。</p>
<h2 id="4-数据库页-Database-Pages"><a href="#4-数据库页-Database-Pages" class="headerlink" title="4 数据库页(Database Pages)"></a>4 数据库页(Database Pages)</h2><p>DBMS通过页（固定大小的数据块）的形式来组织数据库。页可以包含不同类型的数据，如数据项(tuples)、索引(indexes)等。大多数系统不会在同一个页中混合不同类型的数据。</p>
<p>每个页都有一个唯一的标识。如果数据库是单文件构成的，那么页的ID可以是文件内的偏移量。大多数的DBMS通过一个间接层来将页ID映射到文件路径和偏移量。当更高层的系统需要某个特定编号的页时，存储管理器将页编号转换成对应的文件和偏移量来找到特定的页。</p>
<p>​        </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/27/读Paper-DeepFool算法简介/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="青檀">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/27/读Paper-DeepFool算法简介/" itemprop="url">读Paper|DeepFool算法简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-27T01:03:48+08:00">
                2019-08-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>​    DeepFool也是一种基于梯度的白盒攻击算法（与FGSM类似），由Seyed-Mohsen Moosavi-Dezfooli等人在<a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">DeepFool: a simple and accurate method to fool deep neural networks</a> 一文中提出。DeepFool算法不用指定学习速率$\varepsilon$，可以计算出比FGSM算法更小的扰动来达到攻击的目的。</p>
<h1 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h1><p>​    论文中分别提出了针对二分类和多分类的DeepFool算法，并在不同的模型和数据集上进行了实验。</p>
<h2 id="二分类问题"><a href="#二分类问题" class="headerlink" title="二分类问题"></a>二分类问题</h2><p>​    下图为论文中摘取的二分类问题示例，为了改变分类器的决策，在图片上叠加的最小扰动就是$x_{0}$到$f(x)$垂直方向的距离$r_{*}(x)$。</p>
<p>​                                <img src="/assets/deepfool-1.png" alt="deepfool-1"></p>
<p>​    $r_{*}(x)$的解析解可用下式表示.</p>
<p>根据下式，可以很容易地计算得到 $r_{*}(x)$，但是这个扰动值只能使样本达到分类面，而不足以越过，</p>
<p>故最终的扰动值为 $r_{*}(1+\eta)$，$\eta\ll1$，实验中一般取0.02。</p>
<p>​                            <img src="/assets/deepfool-2.png" alt="deepfool-2">            </p>
<p>​    算法伪代码描述如下：</p>
<p><img src="/assets/deepfool-3.png" alt="deepfool-3">                                            </p>
<h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>​    下图为多分类器的示意图，图中实线表示分类器真实的分类超平面，而虚线则代表近似的线性分类超平面，在每次迭代过程中，总是基于当前的迭代值，计算一组近似的线性分类超平面，并根据这组近似超平面，计算扰动，并进行迭代得到下一次的迭代值。</p>
<p><img src="/assets/deepfool-4.png" alt="deepfool-4"></p>
<p>​    算法伪代码描述如下（移动距离比较小，参数矩阵可以用梯度代替）：</p>
<p><img src="/assets/deepfool-5.png" alt="deepfool-5"></p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deepfool_attack</span><span class="params">(sess,</span></span></span><br><span class="line"><span class="function"><span class="params">                    x,</span></span></span><br><span class="line"><span class="function"><span class="params">                    predictions,</span></span></span><br><span class="line"><span class="function"><span class="params">                    logits,</span></span></span><br><span class="line"><span class="function"><span class="params">                    grads,</span></span></span><br><span class="line"><span class="function"><span class="params">                    sample,</span></span></span><br><span class="line"><span class="function"><span class="params">                    nb_candidate,</span></span></span><br><span class="line"><span class="function"><span class="params">                    overshoot,</span></span></span><br><span class="line"><span class="function"><span class="params">                    max_iter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    clip_min,</span></span></span><br><span class="line"><span class="function"><span class="params">                    clip_max,</span></span></span><br><span class="line"><span class="function"><span class="params">                    feed=None)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  TensorFlow implementation of DeepFool.</span></span><br><span class="line"><span class="string">  Paper link: see https://arxiv.org/pdf/1511.04599.pdf</span></span><br><span class="line"><span class="string">  :param sess: TF session</span></span><br><span class="line"><span class="string">  :param x: The input placeholder</span></span><br><span class="line"><span class="string">  :param predictions: The model's sorted symbolic output of logits, only the</span></span><br><span class="line"><span class="string">                     top nb_candidate classes are contained</span></span><br><span class="line"><span class="string">  :param logits: The model's unnormalized output tensor (the input to</span></span><br><span class="line"><span class="string">                 the softmax layer)</span></span><br><span class="line"><span class="string">  :param grads: Symbolic gradients of the top nb_candidate classes, procuded</span></span><br><span class="line"><span class="string">               from gradient_graph</span></span><br><span class="line"><span class="string">  :param sample: Numpy array with sample input</span></span><br><span class="line"><span class="string">  :param nb_candidate: The number of classes to test against, i.e.,</span></span><br><span class="line"><span class="string">                       deepfool only consider nb_candidate classes when</span></span><br><span class="line"><span class="string">                       attacking(thus accelerate speed). The nb_candidate</span></span><br><span class="line"><span class="string">                       classes are chosen according to the prediction</span></span><br><span class="line"><span class="string">                       confidence during implementation.</span></span><br><span class="line"><span class="string">  :param overshoot: A termination criterion to prevent vanishing updates</span></span><br><span class="line"><span class="string">  :param max_iter: Maximum number of iteration for DeepFool</span></span><br><span class="line"><span class="string">  :param clip_min: Minimum value for components of the example returned</span></span><br><span class="line"><span class="string">  :param clip_max: Maximum value for components of the example returned</span></span><br><span class="line"><span class="string">  :return: Adversarial examples</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  adv_x = copy.copy(sample)</span><br><span class="line">  <span class="comment"># Initialize the loop variables</span></span><br><span class="line">  iteration = <span class="number">0</span></span><br><span class="line">  current = utils_tf.model_argmax(sess, x, logits, adv_x, feed=feed)</span><br><span class="line">  <span class="keyword">if</span> current.shape == ():</span><br><span class="line">    current = np.array([current])</span><br><span class="line">  w = np.squeeze(np.zeros(sample.shape[<span class="number">1</span>:]))  <span class="comment"># same shape as original image</span></span><br><span class="line">  r_tot = np.zeros(sample.shape)</span><br><span class="line">  original = current  <span class="comment"># use original label as the reference</span></span><br><span class="line"></span><br><span class="line">  _logger.debug(</span><br><span class="line">      <span class="string">"Starting DeepFool attack up to %s iterations"</span>, max_iter)</span><br><span class="line">  <span class="comment"># Repeat this main loop until we have achieved misclassification</span></span><br><span class="line">  <span class="keyword">while</span> (np.any(current == original) <span class="keyword">and</span> iteration &lt; max_iter):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">5</span> == <span class="number">0</span> <span class="keyword">and</span> iteration &gt; <span class="number">0</span>:</span><br><span class="line">      _logger.info(<span class="string">"Attack result at iteration %s is %s"</span>, iteration, current)</span><br><span class="line">    gradients = sess.run(grads, feed_dict=&#123;x: adv_x&#125;)</span><br><span class="line">    predictions_val = sess.run(predictions, feed_dict=&#123;x: adv_x&#125;)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(sample.shape[<span class="number">0</span>]):</span><br><span class="line">      pert = np.inf</span><br><span class="line">      <span class="keyword">if</span> current[idx] != original[idx]:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, nb_candidate):</span><br><span class="line">        w_k = gradients[idx, k, ...] - gradients[idx, <span class="number">0</span>, ...]</span><br><span class="line">        f_k = predictions_val[idx, k] - predictions_val[idx, <span class="number">0</span>]</span><br><span class="line">        <span class="comment"># adding value 0.00001 to prevent f_k = 0</span></span><br><span class="line">        pert_k = (abs(f_k) + <span class="number">0.00001</span>) / np.linalg.norm(w_k.flatten())</span><br><span class="line">        <span class="keyword">if</span> pert_k &lt; pert:</span><br><span class="line">          pert = pert_k</span><br><span class="line">          w = w_k</span><br><span class="line">      r_i = pert * w / np.linalg.norm(w)</span><br><span class="line">      r_tot[idx, ...] = r_tot[idx, ...] + r_i</span><br><span class="line"></span><br><span class="line">    adv_x = np.clip(r_tot + sample, clip_min, clip_max)</span><br><span class="line">    current = utils_tf.model_argmax(sess, x, logits, adv_x, feed=feed)</span><br><span class="line">    <span class="keyword">if</span> current.shape == ():</span><br><span class="line">      current = np.array([current])</span><br><span class="line">    <span class="comment"># Update loop variables</span></span><br><span class="line">    iteration = iteration + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># need more revision, including info like how many succeed</span></span><br><span class="line">  _logger.info(<span class="string">"Attack result at iteration %s is %s"</span>, iteration, current)</span><br><span class="line">  _logger.info(<span class="string">"%s out of %s become adversarial examples at iteration %s"</span>,</span><br><span class="line">               sum(current != original),</span><br><span class="line">               sample.shape[<span class="number">0</span>],</span><br><span class="line">               iteration)</span><br><span class="line">  <span class="comment"># need to clip this image into the given range</span></span><br><span class="line">  adv_x = np.clip((<span class="number">1</span> + overshoot) * r_tot + sample, clip_min, clip_max)</span><br><span class="line">  <span class="keyword">return</span> adv_x</span><br></pre></td></tr></table></figure>

<p>​    更详细的代码可见看<a href="https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks/deep_fool.py" target="_blank" rel="noopener">这里</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/21/读Paper-FGSM算法简介/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="青檀">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/21/读Paper-FGSM算法简介/" itemprop="url">读Paper|FGSM算法简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-21T21:39:16+08:00">
                2019-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>FGSM（Fast Gradient Sign Method）算法是一种白盒攻击算法，是Ian J. Goodfellow在<a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">Explaining and harnessing adversarial examples</a>一文中提出的。论文中提出，可利用该方法作为一种正则化的手段，从而提高神经网络的准确性，同时增加抵抗对抗攻击的能力。</p>
<h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>​    文章首先解释了线性模型中的对抗样本，针对输入$x$，令扰动输入为$\tilde{x}=x+\eta$，其中$\eta$为很小的变化且$||\eta||_{\infty}&lt;\epsilon$，考虑到<br>$$<br>\mathbf{\omega}^\mathrm{T}\tilde{x}=\mathbf{\omega}^\mathrm{T}x+\mathbf{\omega}^\mathrm{T}\eta.<br>$$<br>$\mathbf{\omega}$为权重向量，对抗扰动通过附加$\mathbf{\omega}^\mathrm{T}\eta$项，从而使激活函数的值而发生变化。因此如果令$\eta=sign(\omega)$（为了保证变化量与梯度方向一致），将每一个维度的微小影响叠加起来，就可以对最终分类结果产生较大的影响。</p>
<p>​    下图是一个经典的对抗样本示例，在ImageNet上训练后的GoogLeNet将原始图片以57.7%的概率识别为熊猫，而在图片上叠加一些扰动后，网络将样本识别以99.3%的概率识别为长臂猿，然而在人眼看来两幅图片几乎没有差别。</p>
<p><img src="/assets/fgsm-1.png" alt="img"></p>
<h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><p>​    令$\theta$为模型参数，$x$为模型输入，$y$为对应的目标，$J(\theta,x,y)$为用来训练神经网络的损失函数：<br>$$<br>\eta=\epsilon \text{sign}(\nabla_{x}J(\theta,x,y)).<br>$$<br>​    简单的讲就是求出损失函数对于输入$x$的梯度，将上式计算出扰动附加到输入$x$上，使$x$朝梯度上升的方向移动，从而使分类结果偏离样本的原始标签。</p>
<h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>算法的tensorflow实现参考了<a href="https://github.com/tensorflow/cleverhans/blob/master/cleverhans/attacks/fast_gradient_method.py" target="_blank" rel="noopener">cleverhans</a>，详细可以参照原github。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fgm</span><span class="params">(x,</span></span></span><br><span class="line"><span class="function"><span class="params">        logits,</span></span></span><br><span class="line"><span class="function"><span class="params">        y=None,</span></span></span><br><span class="line"><span class="function"><span class="params">        eps=<span class="number">0.3</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        ord=np.inf,</span></span></span><br><span class="line"><span class="function"><span class="params">        clip_min=None,</span></span></span><br><span class="line"><span class="function"><span class="params">        clip_max=None,</span></span></span><br><span class="line"><span class="function"><span class="params">        clip_grad=False,</span></span></span><br><span class="line"><span class="function"><span class="params">        targeted=False,</span></span></span><br><span class="line"><span class="function"><span class="params">        sanity_checks=True)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  TensorFlow implementation of the Fast Gradient Method.</span></span><br><span class="line"><span class="string">  :param x: the input placeholder</span></span><br><span class="line"><span class="string">  :param logits: output of model.get_logits</span></span><br><span class="line"><span class="string">  :param y: (optional) A placeholder for the true labels. If targeted</span></span><br><span class="line"><span class="string">            is true, then provide the target label. Otherwise, only provide</span></span><br><span class="line"><span class="string">            this parameter if you'd like to use true labels when crafting</span></span><br><span class="line"><span class="string">            adversarial samples. Otherwise, model predictions are used as</span></span><br><span class="line"><span class="string">            labels to avoid the "label leaking" effect (explained in this</span></span><br><span class="line"><span class="string">            paper: https://arxiv.org/abs/1611.01236). Default is None.</span></span><br><span class="line"><span class="string">            Labels should be one-hot-encoded.</span></span><br><span class="line"><span class="string">  :param eps: the epsilon (input variation parameter)</span></span><br><span class="line"><span class="string">  :param ord: (optional) Order of the norm (mimics NumPy).</span></span><br><span class="line"><span class="string">              Possible values: np.inf, 1 or 2.</span></span><br><span class="line"><span class="string">  :param clip_min: Minimum float value for adversarial example components</span></span><br><span class="line"><span class="string">  :param clip_max: Maximum float value for adversarial example components</span></span><br><span class="line"><span class="string">  :param clip_grad: (optional bool) Ignore gradient components</span></span><br><span class="line"><span class="string">                    at positions where the input is already at the boundary</span></span><br><span class="line"><span class="string">                    of the domain, and the update step will get clipped out.</span></span><br><span class="line"><span class="string">  :param targeted: Is the attack targeted or untargeted? Untargeted, the</span></span><br><span class="line"><span class="string">                   default, will try to make the label incorrect. Targeted</span></span><br><span class="line"><span class="string">                   will instead try to move in the direction of being more</span></span><br><span class="line"><span class="string">                   like y.</span></span><br><span class="line"><span class="string">  :return: a tensor for the adversarial example</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line"></span><br><span class="line">  asserts = []</span><br><span class="line"></span><br><span class="line">  <span class="comment"># If a data range was specified, check that the input was in that range</span></span><br><span class="line">  <span class="keyword">if</span> clip_min <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    asserts.append(utils_tf.assert_greater_equal(</span><br><span class="line">        x, tf.cast(clip_min, x.dtype)))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> clip_max <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    asserts.append(utils_tf.assert_less_equal(x, tf.cast(clip_max, x.dtype)))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Make sure the caller has not passed probs by accident</span></span><br><span class="line">  <span class="keyword">assert</span> logits.op.type != <span class="string">'Softmax'</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># Using model predictions as ground truth to avoid label leaking</span></span><br><span class="line">    preds_max = reduce_max(logits, <span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    y = tf.to_float(tf.equal(logits, preds_max))</span><br><span class="line">    y = tf.stop_gradient(y)</span><br><span class="line">  y = y / reduce_sum(y, <span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Compute loss</span></span><br><span class="line">  loss = softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">  <span class="keyword">if</span> targeted:</span><br><span class="line">    loss = -loss</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Define gradient of loss wrt input</span></span><br><span class="line">  grad, = tf.gradients(loss, x)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> clip_grad:</span><br><span class="line">    grad = utils_tf.zero_out_clipped_grads(grad, x, clip_min, clip_max)</span><br><span class="line"></span><br><span class="line">  optimal_perturbation = optimize_linear(grad, eps, ord)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Add perturbation to original example to obtain adversarial example</span></span><br><span class="line">  adv_x = x + optimal_perturbation</span><br><span class="line"></span><br><span class="line">  <span class="comment"># If clipping is needed, reset all values outside of [clip_min, clip_max]</span></span><br><span class="line">  <span class="keyword">if</span> (clip_min <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">or</span> (clip_max <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">    <span class="comment"># We don't currently support one-sided clipping</span></span><br><span class="line">    <span class="keyword">assert</span> clip_min <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> clip_max <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">    adv_x = utils_tf.clip_by_value(adv_x, clip_min, clip_max)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> sanity_checks:</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies(asserts):</span><br><span class="line">      adv_x = tf.identity(adv_x)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> adv_x</span><br></pre></td></tr></table></figure>

<p>​    简要理解：代码中用targeted变量来标明是否为定向攻击，若取值为False，则会使样本预测值朝梯度上升的方向移动，加大与给定标签logits之间的偏移程度，反之则靠近标签logits。接下来计算样本x与损失函数loss之间的梯度，然后通过optimize_linear函数将偏移量叠加到输入上。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/20/对抗机器学习-Adversarial-Machine-Learning-相关的论文合集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="青檀">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="T's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/20/对抗机器学习-Adversarial-Machine-Learning-相关的论文合集/" itemprop="url">对抗机器学习(Adversarial Machine Learning)相关的论文合集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-20T00:39:42+08:00">
                2019-08-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="预备-基础"><a href="#预备-基础" class="headerlink" title="预备/基础"></a>预备/基础</h1><ol>
<li><a href="https://arxiv.org/abs/1312.6199" target="_blank" rel="noopener">Intriguing properties of neural networks</a></li>
<li><a href="https://arxiv.org/abs/1708.06131" target="_blank" rel="noopener">Evasion Attacks against Machine Learning at Test Time</a></li>
<li><a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">Explaining and Harnessing Adversarial Examples</a>  (FGSM/FGM算法)</li>
</ol>
<h1 id="攻击"><a href="#攻击" class="headerlink" title="攻击"></a>攻击</h1><ol>
<li><a href="https://arxiv.org/abs/1511.07528" target="_blank" rel="noopener">The Limitations of Deep Learning in Adversarial Settings</a></li>
<li><a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">DeepFool: a simple and accurate method to fool deep neural networks</a> (DeepFool算法)</li>
<li><a href="https://arxiv.org/abs/1608.04644" target="_blank" rel="noopener">Towards Evaluating the Robustness of Neural Networks</a></li>
</ol>
<h1 id="迁移性"><a href="#迁移性" class="headerlink" title="迁移性"></a>迁移性</h1><ol>
<li><a href="https://arxiv.org/abs/1605.07277" target="_blank" rel="noopener">Transferability in Machine Learning: from Phenomena to Black-Box Attacks using </a></li>
<li><a href="https://arxiv.org/abs/1605.07277" target="_blank" rel="noopener">Adversarial Samples</a></li>
<li><a href="https://arxiv.org/abs/1611.02770" target="_blank" rel="noopener">Delving into Transferable Adversarial Examples and Black-box Attacks</a></li>
<li><a href="https://arxiv.org/abs/1610.08401" target="_blank" rel="noopener">Universal adversarial perturbations</a></li>
</ol>
<h1 id="对抗样本检测"><a href="#对抗样本检测" class="headerlink" title="对抗样本检测"></a>对抗样本检测</h1><ol>
<li><a href="https://arxiv.org/abs/1702.04267" target="_blank" rel="noopener">On Detecting Adversarial Perturbations</a></li>
<li><a href="https://arxiv.org/abs/1703.00410" target="_blank" rel="noopener">Detecting Adversarial Samples from Artifacts</a></li>
<li><a href="https://arxiv.org/abs/1705.07263" target="_blank" rel="noopener">Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</a></li>
</ol>
<h1 id="有限威胁模型攻击"><a href="#有限威胁模型攻击" class="headerlink" title="有限威胁模型攻击"></a>有限威胁模型攻击</h1><ol>
<li><a href="https://arxiv.org/abs/1708.03999" target="_blank" rel="noopener">ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks </a></li>
<li><a href="https://arxiv.org/abs/1712.04248" target="_blank" rel="noopener">Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models</a></li>
<li><a href="https://arxiv.org/abs/1807.07978" target="_blank" rel="noopener">Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors</a></li>
</ol>
<h1 id="物理攻击"><a href="#物理攻击" class="headerlink" title="物理攻击"></a>物理攻击</h1><ol>
<li><a href="https://arxiv.org/abs/1607.02533" target="_blank" rel="noopener">Adversarial examples in the physical world</a></li>
<li><a href="https://arxiv.org/abs/1707.07397" target="_blank" rel="noopener">Synthesizing Robust Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1707.08945" target="_blank" rel="noopener">Robust Physical-World Attacks on Deep Learning Models</a></li>
</ol>
<h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><ol>
<li><a href="https://arxiv.org/abs/1702.01135" target="_blank" rel="noopener">Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1710.10571" target="_blank" rel="noopener">Certifying Some Distributional Robustness with Principled Adversarial Training</a></li>
</ol>
<h1 id="防御与攻击"><a href="#防御与攻击" class="headerlink" title="防御与攻击"></a>防御与攻击</h1><ol>
<li><a href="https://arxiv.org/abs/1705.09064" target="_blank" rel="noopener">MagNet: a Two-Pronged Defense against Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1711.08478" target="_blank" rel="noopener">MagNet and “Efficient Defenses Against Adversarial Attacks” are Not Robust to Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1706.06083" target="_blank" rel="noopener">Towards Deep Learning Models Resistant to Adversarial Attacks</a></li>
<li><a href="https://arxiv.org/abs/1710.10733" target="_blank" rel="noopener">Attacking the Madry Defense Model with L1-based Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1802.00420" target="_blank" rel="noopener">Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1802.05666" target="_blank" rel="noopener">Adversarial Risk and the Dangers of Evaluating Against Weak Attacks</a></li>
<li><a href="https://arxiv.org/abs/1711.08001" target="_blank" rel="noopener">Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training</a></li>
<li><a href="https://arxiv.org/abs/1805.09190" target="_blank" rel="noopener">Towards the first adversarially robust neural network model on MNIST</a></li>
<li><a href="https://arxiv.org/abs/1702.02284" target="_blank" rel="noopener">Adversarial Attacks on Neural Network Policies</a></li>
<li><a href="https://arxiv.org/abs/1801.01944" target="_blank" rel="noopener">Audio Adversarial Examples: Targeted Attacks on Speech-to-Text</a></li>
<li><a href="https://arxiv.org/abs/1803.01128" target="_blank" rel="noopener">Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples</a></li>
<li><a href="https://arxiv.org/abs/1702.06832" target="_blank" rel="noopener">Adversarial examples for generative models</a></li>
</ol>
<p>更全面的关于对抗机器学习的文献列表，可以参见<a href="https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html" target="_blank" rel="noopener">这篇博客</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">青檀</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">青檀</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
